%% SUTURO Knowledge - Food reasoning module

:- module(suturo_knowledge_foodreasoner,
    [
      graspableOn/2,
      containerOn/2,
      updatePerception/1,
      placedObjectInBox/3,
      clearPerceived/0
    ]).

%% Dependencies
:- use_module(library('knowrob_objects')).
:- use_module(library('comp_spatial')).

%% Register owl namespaces
:- rdf_db:rdf_register_ns(suturo, 'http://www.suturo.de/ontology/hierarchy#', [keep(true)]).
:- rdf_db:rdf_register_ns(knowrob, 'http://ias.cs.tum.edu/kb/knowrob.owl#', [keep(true)]).

%% Constants for value tolerance. Feel free to change this.

%% Number of steps the variance should be increased from 1/steps*variance to full variance. Three steps means
%% to try 1/3*variance, 2/3*variance and variance
%% varianceSteps(10).
%% %% RGB Variance as relative offset (rgb +- variance)
%% rgbColorVariance(A) :- A is round(0.2 * 255).
%% %% H of HSV variance as relative offset (h +- variance)
%% hColorVariance(A) :- A is round(0.2 * 359).
%% %% S and V of HSV variance in percent / 100
%% svColorVariance(A) :- A is 0.2.
%% %% volume variance in percent / 100
%% volumeVariance(0.1).

%% graspableOn(+TableInstanceName, -Out)
%%
%% Returns graspable objects on given table instance
%%
%% 	+TableInstanceName (String): Name of table instance
%%  -Out (List): List of graspable objects. A graspable object is also a list consisting of multiple attributes:
%%               [[edible,name,[centroid_x,centroid_y,centroid_z],frameid,grip-force,use],[...]]
graspableOn(Object, Out) :-
	findall(ObjectInfos, (on_Physical(ObjInst, Object),
			not(rdfs_individual_of(ObjInst, knowrob:'Box-Container')),
			grepInfosToPush(ObjInst, OutObj),
			rdf_has(ObjInst, suturo:'newtonMeter', NM_Raw),
			strip_literal_type(NM_Raw, NM_String),
			atom_number(NM_String, NM),
			append(OutObj, [NM,''], ObjectInfos)), Out).

%% containerOn(+TableInstanceName, -Out)
%%
%% Returns containers on given table instance
%%
%% 	+TableInstanceName (String): Name of table instance
%%  -Out (List): List of containers. A container is also a list consisting of multiple attributes:
%%               [[edible,name,[centroid_x,centroid_y,centroid_z],frameid,grip-force,use],[...]]
containerOn(Object, Out) :-
	findall(ObjectInfos, (on_Physical(ObjInst, Object
			grepInfosToPush(ObjInst, OutObj),
			(storagePlaceFor(ObjInst, knowrob:'FoodOrDrink')->
			append(OutObj, [0,'storage-for-food'], ObjectInfos);append(OutObj, [0,'storage-for-stuff'], ObjectInfos))), Out).

%% updatePerception(-Out)
%%
%% Calls the perception service and runs the recognition on the results.
%% Furthermore, a new PlanningScene is published to the manipulation node.
%%
%%  -Out (Number): Number of recognized objects (Note: These are CURRENTLY recognized objects and
%%                 not the amount of recognized objects in the knowledge base)
updatePerception(Out) :-
	once(
		(savePerception(ObjectList),
		 length(ObjectList, Out);
		 %hackCreateTable(ObjectList),
		 %sendPlanningScene(ObjectList);
		 Out is 0)
		).

%% placedObjectInBox(+Object, +Box, -Out)
%%
%% This removes the given Object from the PlanningScene
%%
%%  +Object (String): Name of object instance
%%  +Container (String): Name of container instance
%%  -Out (Number): Empty list (for planning convenience)
placedObjectInBox(Object, _, Out) :-
	mapconverter(MapConverter),
	jpl_call(MapConverter, 'removeObject', [Object], _),
	jpl_call(MapConverter, 'publishScene', [], _),
	rdf_retractall(Object, knowrob:'latestDetectionOfObject',_),
	Out = [].

%% clearPerceived
%%
%% Clears the database of perceived objects and removes all objects from the Planning Scene
clearPerceived :-
	mapconverter(MapConverter),
	forall(rdf_has(Objects, knowrob:'latestDetectionOfObject',_),
		   (jpl_call(MapConverter, 'removeObject', [Objects], _),
		    jpl_call(MapConverter, 'removeAttachedObject', [Objects], _))
		   ),
	jpl_call(MapConverter, 'publishScene', [], _),
	rdf_retractall(_, knowrob:'latestDetectionOfObject',_).

%% Load lab room semantic map
:- owl_parser:owl_parse('@LOCAL_PACKAGE_PATH@/lib/iai_maps/owl/room.owl', false, false, true).
%% Load suturo objects (either defaultlab_hierarchy.owl, or load OWL file given as argument)
:- current_prolog_flag(argv, Args), last(Args, Arg),
   string_concat('@LOCAL_PACKAGE_PATH@/owl/', Arg, File),
   string_concat(_, '.owl', File) ->
   		owl_parser:owl_parse(File, false, false, true);
   		owl_parser:owl_parse('@LOCAL_PACKAGE_PATH@/owl/lab_hierarchy.owl', false, false, true).

%% Instanciate Java bridges to Perception and Manipulation
:- jpl_new('de.suturo.knowledge.foodreasoner.PerceptionClient',[], PerceptionClient), assert(perception(PerceptionClient)).
:- jpl_new('de.suturo.knowledge.psexport.MapConverter',[], Instance), assert(mapconverter(Instance)).
%% Instanciate Java object classifier
:- jpl_new('de.suturo.knowledge.foodreasoner.ProbabilityClassifier', [], ProbabilityClassifier), assert(probabilityclassifier(ProbabilityClassifier)).
 
%% print out information about the last object classification
%% classificationInfo(List) :-
%%   probabilityclassifier(ProbabilityClassifier), 
%%   jpl_call(ProbabilityClassifier, 'classificationInfo', [], Ret),
%%   writeln(Ret).


%% Constants
shape(0, 'NONE').
shape(1, 'Box').
shape(2, 'Cylinder').
shape(3, 'Sphere').

%$ Accessor predicate for perceived objects
%perceived_object([ID, Label, Volume, Shape], ID, Label, Volume, Shape).

%% This parses float strings from LISP (1.23456789d-123) to prolog float
%% dfloatToFloat(StringDoubleFloat, Float) :-
%% 	atomic_list_concat(List, 'd', StringDoubleFloat),
%% 	atomic_list_concat(List, 'e', FloatString),
%% 	atom_number(FloatString, Float).

%% %% Accessor predicate for containers
%% %% containerObject(ContainerFor, Name, Type,[Centroid_x, Centroid_y, Centroid_z], FrameId).

%% list_min([L|Ls], Min) :- foldl(num_num_min, Ls, L, Min).

%% num_num_min(X, Y, Min) :- Min is min(X, Y).

%% hackCreateTable(ObjectList) :-
%% 	%%findall(Y,(member(ObjectIdentifier,ObjectList),getLatestCoordinatesOfObject(ObjectIdentifier, X , Y ,Z, FrameID)),Y_Coords),
%% 	%%list_min(Y_Coords, Min_Y),
%% 	headElement( ObjectList, Object),
%% 	getLatestCoordinatesOfObject(Object, X , Y ,Z, FrameID),
%% 	rdf_has(Object, knowrob:heightOfObject, OHeight),
%% 	strip_literal_type(OHeight, Height_Raw),
%% 	atom_number(Height_Raw, Height),
%% 	Z_Table is Z - Height,
%% 	createPerceptionInstanceToObject([_, _, _, _, 'kitchen_island_counter_top', _, _, _, _, _, _, _, _, _, 
%% 	 X, Y, Z_Table, FrameID], 'http://ias.cs.tum.edu/kb/knowrob.owl#kitchen_island_counter_top').


grepInfosToPush(ObjectIdentifier, [_edible,_name,[_centroid_x,_centroid_y,_centroid_z],_frameid]) :-
	_name = ObjectIdentifier,
	(rdfs_individual_of(ObjectIdentifier, knowrob:'FoodOrDrink') ->
		_edible =true; _edible=false),
	getLatestCoordinatesOfObject(ObjectIdentifier, _centroid_x,_centroid_y,_centroid_z, _frameid).


%% Retrieves objects from perception and recognizes them. All recognized objects are then saved to the database
savePerception(ObjectInst) :-
	getPerceivedObjectsInfos(DataList, RawPerceivedObjects),
	findall(Instance,(member(Object, DataList),
		%once(recognizeLowestVariance(Object, Instance)),
		createPerceptionInstanceToObject(Object, Instance)), ObjectInst).%
			%createObjectPerception(Object, [], ['VisualPerception'], ObjectInst))).

createPerceptionInstanceToObject([Identifier, Map_FrameId, X_Coord, Y_Coord, Z_Coord, W_Rot, X_Rot, Y_Rot, Z_Rot],
	Identifier) :-
	once(create_perception_instance(['VisualPerception'], Perception)),
    set_object_perception(Identifier, Perception),
    fromQuaterniontoRotation(W_Rot, X_Rot, Y_Rot, Z_Rot, M11, M21, M31, M21, M22, M23, M31, M32, M33),
    set_perception_pose(Perception, [M11,M12,M13,X_Coord,M21,M22,M23,Y_Coord,M31,M32,M33,Z_Coord,0,0,0,0]),
    rdf_assert(Perception, suturo:'frameID', literal(type('http://www.w3.org/2001/XMLSchema#string',Map_FrameId))).

fromQuaterniontoRotation(W,X,Y,Z,M11, M21, M31, M21, M22, M23, M31, M32, M33) :-
	is(M11, 1 - 2 * Y**2 - 2 * Z**2),
	is(M12, 2 * X * Y + 2 * W * Z),
	is(M13, 2 * X * Z - 2 * W * Y),
	is(M21, 2 * X * Y - 2 * W * Z),
	is(M22, 1 - 2 * X**2 - 2 * Z**2),
	is(M23, 2 * Y * Z + 2 * W * X),
	is(M31, 2 * X * Z + 2 * W * Y),
	is(M32, 2 * Y * Z - 2 * W * X),
	is(M33, 1 - 2 * X**2 - 2 * Y**2).



%% createObjectPerception([_, _, _c_volume, _, _recognition_label_2d, _c_shape, _c_color_average_r, _c_color_average_g,
%%  _c_color_average_b, _c_color_average_h, _c_color_average_s, _c_color_average_v, _, _, X_Coord, Y_Coord, Z_Coord,
%%   Odom_FrameId], _, PerceptionTypes, ObjInst) :-
%% 	%% if shape != 0 
%% 	(_c_shape =\= 0 ->
%% 		shape(_c_shape, ShapeString),
%% 		atom_concat('http://ias.cs.tum.edu/kb/knowrob.owl#', ShapeString, Type),
%% 		atom_concat('Got Type Shape ', Type , Log),
%% 		writeln(Log);
%%     	%%else 
%%     	atom_concat('http://ias.cs.tum.edu/kb/knowrob.owl#', 'Thing', Type),
%%     	atom_concat('Got Type Thing ', Type , Log),
%% 		writeln(Log)),
%%     (_recognition_label_2d \= '' ->
%%     	atom_concat('http://ias.cs.tum.edu/kb/knowrob.owl#', _recognition_label_2d, ObjInst),
%%     	rdf_assert(ObjInst, rdf:type, Type); 
%%     	rdf_instance_from_class(Type, ObjInst)),
%%     assertRGBColors(ObjInst, _c_color_average_r, _c_color_average_g, _c_color_average_b),
%%     assertRGBColors(ObjInst, _c_color_average_h, _c_color_average_s, _c_color_average_v),
%%    	rdf_assert(ObjInst, knowrob:'volumeOfObject', literal(type('http://www.w3.org/2001/XMLSchema#int',_c_volume))),
%%     create_perception_instance(PerceptionTypes, Perception),
%%     set_object_perception(ObjInst, Perception),
%%     set_perception_pose(Perception, [1,0,0,X_Coord,0,1,0,Y_Coord,0,0,1,Z_Coord,0,0,0,0]),
%%     rdf_assert(Perception, suturo:'frameID', literal(type('http://www.w3.org/2001/XMLSchema#string',Odom_FrameId))).

%% assertRGBColors(ObjInst, R_Color, G_Color, B_Color) :-
%% 	rdf_assert(ObjInst, rdf:type, knowrob:'RGBAverageColor'),
%% 	rdf_assert(ObjInst, suturo:'rColorValue', literal(type('http://www.w3.org/2001/XMLSchema#byte',R_Color))),
%% 	rdf_assert(ObjInst, suturo:'gColorValue', literal(type('http://www.w3.org/2001/XMLSchema#byte',G_Color))),
%% 	rdf_assert(ObjInst, suturo:'bColorValue', literal(type('http://www.w3.org/2001/XMLSchema#byte',B_Color))).

%% assertRGBColors(ObjInst, H_Color, S_Color, V_Color) :-
%% 	rdf_assert(ObjInst, rdf:type, knowrob:'HSVAverageColor'),
%% 	rdf_assert(ObjInst, suturo:'HColorValue', literal(type('http://www.w3.org/2001/XMLSchema#int',H_Color))),
%% 	rdf_assert(ObjInst, suturo:'SColorValue', literal(type('http://www.w3.org/2001/XMLSchema#float',S_Color))),
%% 	rdf_assert(ObjInst, suturo:'VColorValue', literal(type('http://www.w3.org/2001/XMLSchema#float',V_Color))).


%% recognizeLowestVariance(Object, ObjectIdentifier) :-
%% 	varianceSteps(Steps),
%% 	between(1, Steps, Step),
%% 	recognizedObject(Object, Step, ObjectIdentifier).

%% recognizedObject([_c_id, _c_centroid, _c_volume, _frame_id,
%%  _recognition_label_2d, _c_shape, _c_color_average_r, _c_color_average_g, _c_color_average_b,
%%  _c_color_average_h, _c_color_average_s, _c_color_average_v, _c_hue_histogram, _c_hue_histogram_quality, 
%%  X_Coord, Y_Coord, Z_Coord, Odom_FrameId], Step, ObjectIdentifier) :-
%% 	write('Step nr: '),
%% 	writeln(Step),

%%   writeln('Zero using probability for matching'),
%%   probabilityclassifier(ProbabilityClassifier),
%%   jpl_call(ProbabilityClassifier, 'classifyPerceivedObject', [_c_color_average_h, _c_volume], ObjectIdentifier),
%%   writeln(ObjectIdentifier),
%%   classificationInfo(L).
  
%% recognitionLabelExisting(ObjectIdentifier, Label) :-
%% 	atom_concat('http://www.suturo.de/ontology/hierarchy#', Label, ObjectIdentifier),
%% 	rdf_has(ObjectIdentifier, _ , _).

%% shapeIsFitting(ObjectIdentifier, Shape_Raw) :-
%% 	shape(Shape_Raw, ShapeString),
%% 	atom_concat('http://ias.cs.tum.edu/kb/knowrob.owl#', ShapeString, Shape),
%% 	rdf_has(ObjectIdentifier, rdf:type ,Shape).

%% volumeInRange(ObjectIdentifier, Step, Volume) :-
%% 	rdf_has(ObjectIdentifier , knowrob:'volumeOfObject', Obj_Vol),
%% 	strip_literal_type(Obj_Vol, VOL_Raw),
%% 	atom_number(VOL_Raw, VOL),
%% 	volumeVariance(VarRaw),
%% 	varianceSteps(Steps),
%% 	Var is (Step/Steps*VarRaw),
%% 	Min is VOL * (1 - Var),
%% 	Max is VOL * (1 + Var),
%% 	Min =< Volume,
%% 	Max >= Volume.

%% rgbIsFitting(ObjectIdentifier, Step, R_Color, G_Color, B_Color) :-
%% 	rdf_has(ObjectIdentifier, suturo:rColorValue , Obj_R_Color),
%% 	rgbColorVariance(RGBVarianceRaw),
%% 	varianceSteps(Steps),
%% 	RGBVariance is (Step/Steps*RGBVarianceRaw),
%% 	strip_literal_type(Obj_R_Color, R_Raw),
%% 	atom_number(R_Raw, R),
%% 	MinR is R - RGBVariance,
%% 	MaxR is R + RGBVariance,
%% 	MinR =< R_Color,
%% 	MaxR >= R_Color,
%% 	rdf_has(ObjectIdentifier, suturo:gColorValue , Obj_G_Color),
%% 	strip_literal_type(Obj_G_Color, G_Raw),
%% 	atom_number(G_Raw, G),
%% 	MinG is G - RGBVariance,
%% 	MaxG is G + RGBVariance,
%% 	MinG =< G_Color,
%% 	MaxG >= G_Color,
%% 	rdf_has(ObjectIdentifier, suturo:bColorValue , Obj_B_Color),
%% 	strip_literal_type(Obj_B_Color, B_Raw),
%% 	atom_number(B_Raw, B),	
%% 	MinB is B - RGBVariance,
%% 	MaxB is B + RGBVariance,
%% 	MinB =< B_Color,
%% 	MaxB >= B_Color.

%% hsvIsFitting(ObjectIdentifier, Step, H_Value, S_Value, V_Value) :-
%% 	rdf_has(ObjectIdentifier, suturo:hColorValue , Obj_H_Value),
%% 	hColorVariance(HVarianceRaw),
%% 	varianceSteps(Steps),
%% 	HVariance is (Step/Steps*HVarianceRaw),
%% 	strip_literal_type(Obj_H_Value, H_Raw),
%% 	atom_number(H_Raw, H),
%% 	MinH is round(H - HVariance) mod 360,
%% 	MaxH is round(H + HVariance) mod 360,
%% 	(((H - HVariance) < 0; (H + HVariance) >359) -> 
%% 		(MinH =< H_Value; MaxH >= H_Value);
%% 		((MinH =< H_Value), (MaxH >= H_Value)) ),
%% 	rdf_has(ObjectIdentifier, suturo:sColorValue , Obj_S_Value),
%% 	svColorVariance(SVVarianceRaw),
%% 	SVVariance is (Step/Steps*SVVarianceRaw),
%% 	strip_literal_type(Obj_S_Value, S_Raw),
%% 	atom_number(S_Raw, S),
%% 	MinS is S - SVVariance,
%% 	MaxS is S + SVVariance,
%% 	MinS =< S_Value,
%% 	MaxS >= S_Value,
%% 	rdf_has(ObjectIdentifier, suturo:vColorValue , Obj_V_Value),
%% 	strip_literal_type(Obj_V_Value, V_Raw),
%% 	atom_number(V_Raw, V),
%% 	MinV is V - SVVariance,
%% 	MaxV is V + SVVariance,
%% 	MinV =< V_Value,
%% 	MaxV >= V_Value.

%headElement([Head| _], Head).

%% This is a test for JNI integration
getPerceivedObjectsInfos(PODataList, RawPerceivedObjects) :-
	perception(PrologBridge),
	jpl_call(PrologBridge, 'perceive', [], Out_raw),
	jpl_get(Out_raw,'length',Length),
	is(Indizees, Length-1),
	findall(POData,processPerceivedObjects(Out_raw, Indizees, POData), PODataList).

processPerceivedObjects(Out_raw, Indizees, [Identifier, Map_FrameId, X_Coord, Y_Coord, Z_Coord, W_Rot, X_Rot, Y_Rot, Z_Rot]) :-
	perception(PrologBridge),
	numlist(0,Indizees,IndexList),
	member(Index, IndexList),
	jpl_get(Out_raw,Index,Perceived_object),
	jpl_call(PrologBridge, 'getMapCoords', [Perceived_object], MapCoords_Raw),
	jpl_call(PrologBridge, 'getCuboidPose', [Perceived_object], Cuboid_Raw),
	jpl_get(Perceived_object, 'Identifier', Identifier)

	jpl_call(MapCoords_Raw, 'getData', [], Point_Raw),
	jpl_get(Point_Raw,'x', X_Coord),
	jpl_get(Point_Raw,'y', Y_Coord),
	jpl_get(Point_Raw,'z', Z_Coord),
	jpl_get(Point_Raw,'frameID', Map_FrameId),

	jpl_call(Cuboid_Raw, 'getData', [], Pose_Raw),
	jpl_get(Pose_Raw,'w', W_Rot),
	jpl_get(Pose_Raw,'x', X_Rot),
	jpl_get(Pose_Raw,'y', Y_Rot),
	jpl_get(Pose_Raw,'z', Z_Rot),
	jpl_get(Pose_Raw,'frameID', Map_FrameId2).
	

%% sendPlanningScene(ObjectList) :-
%% 	mapconverter(MapConverter),
%% 	foreach(member(Object, ObjectList), sendSingleObject(Object)),
%% 	jpl_call(MapConverter, 'publishScene', [], _).

getLatestCoordinatesOfObject(ObjectIdentifier, X , Y ,Z, FrameID) :-
	rdf_has(ObjectIdentifier, knowrob:latestDetectionOfObject, ObjectDetection),
	rdf_has(ObjectDetection, suturo:frameID, FrameID_Raw),
	strip_literal_type(FrameID_Raw, FrameID),
	rdf_has(ObjectDetection, knowrob:eventOccursAt, RotationMatrix),
	rdf_has(RotationMatrix, knowrob:m03, X_Coord),
	strip_literal_type(X_Coord , X1),
	(rdf_has(ObjectIdentifier, suturo:xOffset, X_Offset) ->
		strip_literal_type(X_Offset , X2S), atom_number(X2S, X2), X is (X1+X2);
		X is X1),
	rdf_has(RotationMatrix, knowrob:m13, Y_Coord),
	strip_literal_type(Y_Coord, Y1),
	(rdf_has(ObjectIdentifier, suturo:yOffset, Y_Offset) ->
		strip_literal_type(Y_Offset , Y2S), atom_number(Y2S, Y2), Y is (Y1+Y2);
		Y is Y1),
	rdf_has(RotationMatrix, knowrob:m23, Z_Coord),
	strip_literal_type(Z_Coord, Z1),
	(rdf_has(ObjectIdentifier, suturo:zOffset, Z_Offset) ->
		strip_literal_type(Z_Offset , Z2S), atom_number(Z2S, Z2), Z is (Z1+Z2);
		Z is Z1).

%% sendSingleObject(ObjectIdentifier) :-
%% 	mapconverter(MapConverter),
%% 	rdf_has(ObjectIdentifier, knowrob:heightOfObject, OHeight),
%% 	strip_literal_type(OHeight, Height_Raw),
%% 	atom_number(Height_Raw, Height),
%% 	rdf_has(ObjectIdentifier, knowrob:depthOfObject, ODepth),
%% 	strip_literal_type(ODepth, Depth_Raw),
%% 	atom_number(Depth_Raw, Depth),
%% 	rdf_has(ObjectIdentifier, knowrob:widthOfObject, OWidth),
%% 	strip_literal_type(OWidth, Width_Raw),
%% 	atom_number(Width_Raw, Width),
%% 	getLatestCoordinatesOfObject(ObjectIdentifier, X_Coord, Y_Coord, Z_Coord, FrameID),
%% 	jpl_call(MapConverter, 'addBox', [ObjectIdentifier, Depth, Width, Height, X_Coord, Y_Coord, Z_Coord, FrameID], _).
