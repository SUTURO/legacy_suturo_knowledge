%% SUTURO Knowledge - Food reasoning module

:- module(suturo_knowledge_foodreasoner,
    [
      graspableOn/2,
      containerOn/2,
      updatePerception/1,
      placedObjectInBox/3,
      clearPerceived/0
    ]).

%% Dependencies
:- use_module(library('knowrob_objects')).
:- use_module(library('comp_spatial')).

%% Register owl namespaces
:- rdf_db:rdf_register_ns(suturo, 'http://www.suturo.de/ontology/hierarchy#', [keep(true)]).
:- rdf_db:rdf_register_ns(knowrob, 'http://ias.cs.tum.edu/kb/knowrob.owl#', [keep(true)]).

%% Constants for value tolerance. Feel free to change this.

%% Number of steps the variance should be increased from 1/steps*variance to full variance. Three steps means
%% to try 1/3*variance, 2/3*variance and variance
varianceSteps(10).
%% RGB Variance as relative offset (rgb +- variance)
rgbColorVariance(A) :- A is round(0.2 * 255).
%% H of HSV variance as relative offset (h +- variance)
hColorVariance(A) :- A is round(0.2 * 359).
%% S and V of HSV variance in percent / 100
svColorVariance(A) :- A is 0.2.
%% volume variance in percent / 100
volumeVariance(0.1).

%% graspableOn(+TableInstanceName, -Out)
%%
%% Returns graspable objects on given table instance
%%
%% 	+TableInstanceName (String): Name of table instance
%%  -Out (List): List of graspable objects. A graspable object is also a list consisting of multiple attributes:
%%               [[edible,name,[centroid_x,centroid_y,centroid_z],frameid,grip-force,use],[...]]
graspableOn(_, Out) :-
	findall(ObjectInfos, (on_Physical(ObjInst, 'http://ias.cs.tum.edu/kb/knowrob.owl#kitchen_island_counter_top'),
			not(rdfs_individual_of(ObjInst, knowrob:'Box-Container')),
			grepInfosToPush(ObjInst, OutObj),
			rdf_has(ObjInst, suturo:'newtonMeter', NM_Raw),
			strip_literal_type(NM_Raw, NM_String),
			atom_number(NM_String, NM),
			append(OutObj, [NM,''], ObjectInfos)), Out).

%% containerOn(+TableInstanceName, -Out)
%%
%% Returns containers on given table instance
%%
%% 	+TableInstanceName (String): Name of table instance
%%  -Out (List): List of containers. A container is also a list consisting of multiple attributes:
%%               [[edible,name,[centroid_x,centroid_y,centroid_z],frameid,grip-force,use],[...]]
containerOn(_, Out) :-
	findall(ObjectInfos, (on_Physical(ObjInst, 'http://ias.cs.tum.edu/kb/knowrob.owl#kitchen_island_counter_top'),
			rdfs_individual_of(ObjInst, knowrob:'Box-Container'),
			grepInfosToPush(ObjInst, OutObj),
			(storagePlaceFor(ObjInst, knowrob:'FoodOrDrink')->
			append(OutObj, [0,'storage-for-food'], ObjectInfos);append(OutObj, [0,'storage-for-stuff'], ObjectInfos))), Out).

%% updatePerception(-Out)
%%
%% Calls the perception service and runs the recognition on the results.
%% Furthermore, a new PlanningScene is published to the manipulation node.
%%
%%  -Out (Number): Number of recognized objects (Note: These are CURRENTLY recognized objects and
%%                 not the amount of recognized objects in the knowledge base)
updatePerception(Out) :-
	once(
		(savePerception(ObjectList),
		 length(ObjectList, Out),
		 hackCreateTable(ObjectList),
		 sendPlanningScene(ObjectList);
		 Out is 0)
		).

%% placedObjectInBox(+Object, +Box, -Out)
%%
%% This removes the given Object from the PlanningScene
%%
%%  +Object (String): Name of object instance
%%  +Container (String): Name of container instance
%%  -Out (Number): Empty list (for planning convenience)
placedObjectInBox(Object, _, Out) :-
	mapconverter(MapConverter),
	jpl_call(MapConverter, 'removeObject', [Object], _),
	jpl_call(MapConverter, 'publishScene', [], _),
	rdf_retractall(Object, knowrob:'latestDetectionOfObject',_),
	Out = [].

%% clearPerceived
%%
%% Clears the database of perceived objects and removes all objects from the Planning Scene
clearPerceived :-
	mapconverter(MapConverter),
	forall(rdf_has(Objects, knowrob:'latestDetectionOfObject',_),
		   (jpl_call(MapConverter, 'removeObject', [Objects], _),
		    jpl_call(MapConverter, 'removeAttachedObject', [Objects], _))
		   ),
	jpl_call(MapConverter, 'publishScene', [], _),
	rdf_retractall(_, knowrob:'latestDetectionOfObject',_).

%% Load lab room semantic map
:- owl_parser:owl_parse('@IAI_MAPS_PACKAGE_PATH@/owl/room.owl', false, false, true).
%% Load suturo objects (either defaultlab_hierarchy.owl, or load OWL file given as argument)
:- current_prolog_flag(argv, Args), last(Args, Arg),
   string_concat('@LOCAL_PACKAGE_PATH@/owl/', Arg, File),
   string_concat(_, '.owl', File) ->
   		owl_parser:owl_parse(File, false, false, true);
   		owl_parser:owl_parse('@LOCAL_PACKAGE_PATH@/owl/lab_hierarchy.owl', false, false, true).

%% Instanciate Java bridges to Perception and Manipulation
:- jpl_new('de.suturo.knowledge.foodreasoner.PerceptionClient',[], PerceptionClient), assert(perception(PerceptionClient)).
:- jpl_new('de.suturo.knowledge.psexport.MapConverter',[], Instance), assert(mapconverter(Instance)).
%% Instanciate Java object classifier
:- jpl_new('de.suturo.knowledge.foodreasoner.ProbabilityClassifier', [], ProbabilityClassifier), assert(probabilityclassifier(ProbabilityClassifier)).


%% Gets classification information of one object
%%getObjectProbabilities(Instance, HueMean, HueSD, VolumeMean, VolumeSD) :-
%%  rdf_has(Instance, suturo:'statisticalHueMean', HueMeanRaw),
%%  rdf_has(Instance, suturo:'statisticalHueStandardDeviation', HueSDRaw),
%%  rdf_has(Instance, suturo:'statisticalVolumeMean', VolumeMeanRaw),
%%  rdf_has(Instance, suturo:'statisticalVolumeStandardDeviation', VolumeSDRaw),
%%  strip_literal_type(HueMeanRaw, HueMean),
%%  strip_literal_type(HueSDRaw, HueSD),
%%  strip_literal_type(VolumeMeanRaw, VolumeMean),
%%  strip_literal_type(VolumeSDRaw, VolumeSD).

%% sends all object classification information available to java class
%%sendObjectProbabilitiesToJava(List) :-
%%  probabilityclassifier(ProbabilityClassifier),
%%  findall([Instance, HueMean, HueSD, VolumeMean, VolumeSD],
%%    (
%%      getObjectProbabilities(Instance, HueMean, HueSD, VolumeMean, VolumeSD), 
%%      jpl_call(ProbabilityClassifier, 'appendToObjectsList', [Instance, HueMean, HueSD, VolumeMean, VolumeSD], ColRet),
%%      writeln(ColRet)
%%    ),
%%    List).
 
%% print out information about the last object classification
classificationInfo(List) :-
  probabilityclassifier(ProbabilityClassifier), 
  jpl_call(ProbabilityClassifier, 'classificationInfo', [], Ret),
  writeln(Ret).


%% Constants
shape(0, 'NONE').
shape(1, 'Box').
shape(2, 'Cylinder').
shape(3, 'Sphere').

%$ Accessor predicate for perceived objects
perceived_object([ID, Label, Volume, Shape], ID, Label, Volume, Shape).

%% This parses float strings from LISP (1.23456789d-123) to prolog float
dfloatToFloat(StringDoubleFloat, Float) :-
	atomic_list_concat(List, 'd', StringDoubleFloat),
	atomic_list_concat(List, 'e', FloatString),
	atom_number(FloatString, Float).

%% Accessor predicate for containers
%% containerObject(ContainerFor, Name, Type,[Centroid_x, Centroid_y, Centroid_z], FrameId).

list_min([L|Ls], Min) :- foldl(num_num_min, Ls, L, Min).

num_num_min(X, Y, Min) :- Min is min(X, Y).

hackCreateTable(ObjectList) :-
	%%findall(Y,(member(ObjectIdentifier,ObjectList),getLatestCoordinatesOfObject(ObjectIdentifier, X , Y ,Z, FrameID)),Y_Coords),
	%%list_min(Y_Coords, Min_Y),
	headElement( ObjectList, Object),
	getLatestCoordinatesOfObject(Object, X , Y ,Z, FrameID),
	rdf_has(Object, knowrob:heightOfObject, OHeight),
	strip_literal_type(OHeight, Height_Raw),
	atom_number(Height_Raw, Height),
	Z_Table is Z - Height,
	createPerceptionInstanceToObject([_, _, _, _, 'kitchen_island_counter_top', _, _, _, _, _, _, _, _, _, 
	 X, Y, Z_Table, FrameID], 'http://ias.cs.tum.edu/kb/knowrob.owl#kitchen_island_counter_top').


grepInfosToPush(ObjectIdentifier, [_edible,_name,[_centroid_x,_centroid_y,_centroid_z],_frameid]) :-
	_name = ObjectIdentifier,
	(rdfs_individual_of(ObjectIdentifier, knowrob:'FoodOrDrink') ->
		_edible =true; _edible=false),
	getLatestCoordinatesOfObject(ObjectIdentifier, _centroid_x,_centroid_y,_centroid_z, _frameid).


%% Retrieves objects from perception and recognizes them. All recognized objects are then saved to the database
savePerception(ObjectInst) :-
	getPerceivedObjectsInfos(DataList),
	findall(Instance,(member(Object, DataList),
		once(recognizeLowestVariance(Object, Instance)),
		createPerceptionInstanceToObject(Object, Instance)), ObjectInst).%
			%createObjectPerception(Object, [], ['VisualPerception'], ObjectInst))).

createPerceptionInstanceToObject([_c_id, _c_centroid, _c_volume, _frame_id,
 _recognition_label_2d, _c_shape, _c_color_average_r, _c_color_average_g, _c_color_average_b,
 _c_color_average_h, _c_color_average_s, _c_color_average_v, _c_hue_histogram, _c_hue_histogram_quality, 
 X_Coord, Y_Coord, Z_Coord, Odom_FrameId], ObjInst) :-
	once(create_perception_instance(['VisualPerception'], Perception)),
    set_object_perception(ObjInst, Perception),
    set_perception_pose(Perception, [1,0,0,X_Coord,0,1,0,Y_Coord,0,0,1,Z_Coord,0,0,0,0]),
    rdf_assert(Perception, suturo:'frameID', literal(type('http://www.w3.org/2001/XMLSchema#string',Odom_FrameId))).

createObjectPerception([_, _, _c_volume, _, _recognition_label_2d, _c_shape, _c_color_average_r, _c_color_average_g,
 _c_color_average_b, _c_color_average_h, _c_color_average_s, _c_color_average_v, _, _, X_Coord, Y_Coord, Z_Coord,
  Odom_FrameId], _, PerceptionTypes, ObjInst) :-
	%% if shape != 0 
	(_c_shape =\= 0 ->
		shape(_c_shape, ShapeString),
		atom_concat('http://ias.cs.tum.edu/kb/knowrob.owl#', ShapeString, Type),
		atom_concat('Got Type Shape ', Type , Log),
		writeln(Log);
    	%%else 
    	atom_concat('http://ias.cs.tum.edu/kb/knowrob.owl#', 'Thing', Type),
    	atom_concat('Got Type Thing ', Type , Log),
		writeln(Log)),
    (_recognition_label_2d \= '' ->
    	atom_concat('http://ias.cs.tum.edu/kb/knowrob.owl#', _recognition_label_2d, ObjInst),
    	rdf_assert(ObjInst, rdf:type, Type); 
    	rdf_instance_from_class(Type, ObjInst)),
    assertRGBColors(ObjInst, _c_color_average_r, _c_color_average_g, _c_color_average_b),
    assertRGBColors(ObjInst, _c_color_average_h, _c_color_average_s, _c_color_average_v),
   	rdf_assert(ObjInst, knowrob:'volumeOfObject', literal(type('http://www.w3.org/2001/XMLSchema#int',_c_volume))),
    create_perception_instance(PerceptionTypes, Perception),
    set_object_perception(ObjInst, Perception),
    set_perception_pose(Perception, [1,0,0,X_Coord,0,1,0,Y_Coord,0,0,1,Z_Coord,0,0,0,0]),
    rdf_assert(Perception, suturo:'frameID', literal(type('http://www.w3.org/2001/XMLSchema#string',Odom_FrameId))).

assertRGBColors(ObjInst, R_Color, G_Color, B_Color) :-
	rdf_assert(ObjInst, rdf:type, knowrob:'RGBAverageColor'),
	rdf_assert(ObjInst, suturo:'rColorValue', literal(type('http://www.w3.org/2001/XMLSchema#byte',R_Color))),
	rdf_assert(ObjInst, suturo:'gColorValue', literal(type('http://www.w3.org/2001/XMLSchema#byte',G_Color))),
	rdf_assert(ObjInst, suturo:'bColorValue', literal(type('http://www.w3.org/2001/XMLSchema#byte',B_Color))).

assertRGBColors(ObjInst, H_Color, S_Color, V_Color) :-
	rdf_assert(ObjInst, rdf:type, knowrob:'HSVAverageColor'),
	rdf_assert(ObjInst, suturo:'HColorValue', literal(type('http://www.w3.org/2001/XMLSchema#int',H_Color))),
	rdf_assert(ObjInst, suturo:'SColorValue', literal(type('http://www.w3.org/2001/XMLSchema#float',S_Color))),
	rdf_assert(ObjInst, suturo:'VColorValue', literal(type('http://www.w3.org/2001/XMLSchema#float',V_Color))).


recognizeLowestVariance(Object, ObjectIdentifier) :-
	varianceSteps(Steps),
	between(1, Steps, Step),
	recognizedObject(Object, Step, ObjectIdentifier).

recognizedObject([_c_id, _c_centroid, _c_volume, _frame_id,
 _recognition_label_2d, _c_shape, _c_color_average_r, _c_color_average_g, _c_color_average_b,
 _c_color_average_h, _c_color_average_s, _c_color_average_v, _c_hue_histogram, _c_hue_histogram_quality, 
 X_Coord, Y_Coord, Z_Coord, Odom_FrameId], Step, ObjectIdentifier) :-
	write('Step nr: '),
	writeln(Step),

  writeln('Zero using probability for matching'),
  probabilityclassifier(ProbabilityClassifier),
  jpl_call(ProbabilityClassifier, 'classifyPerceivedObject', [_c_color_average_h, _c_volume], ObjectIdentifier),
  writeln(ObjectIdentifier),
  classificationInfo(L).
  
recognitionLabelExisting(ObjectIdentifier, Label) :-
	atom_concat('http://www.suturo.de/ontology/hierarchy#', Label, ObjectIdentifier),
	rdf_has(ObjectIdentifier, _ , _).

shapeIsFitting(ObjectIdentifier, Shape_Raw) :-
	shape(Shape_Raw, ShapeString),
	atom_concat('http://ias.cs.tum.edu/kb/knowrob.owl#', ShapeString, Shape),
	rdf_has(ObjectIdentifier, rdf:type ,Shape).

volumeInRange(ObjectIdentifier, Step, Volume) :-
	rdf_has(ObjectIdentifier , knowrob:'volumeOfObject', Obj_Vol),
	strip_literal_type(Obj_Vol, VOL_Raw),
	atom_number(VOL_Raw, VOL),
	volumeVariance(VarRaw),
	varianceSteps(Steps),
	Var is (Step/Steps*VarRaw),
	Min is VOL * (1 - Var),
	Max is VOL * (1 + Var),
	Min =< Volume,
	Max >= Volume.

rgbIsFitting(ObjectIdentifier, Step, R_Color, G_Color, B_Color) :-
	rdf_has(ObjectIdentifier, suturo:rColorValue , Obj_R_Color),
	rgbColorVariance(RGBVarianceRaw),
	varianceSteps(Steps),
	RGBVariance is (Step/Steps*RGBVarianceRaw),
	strip_literal_type(Obj_R_Color, R_Raw),
	atom_number(R_Raw, R),
	MinR is R - RGBVariance,
	MaxR is R + RGBVariance,
	MinR =< R_Color,
	MaxR >= R_Color,
	rdf_has(ObjectIdentifier, suturo:gColorValue , Obj_G_Color),
	strip_literal_type(Obj_G_Color, G_Raw),
	atom_number(G_Raw, G),
	MinG is G - RGBVariance,
	MaxG is G + RGBVariance,
	MinG =< G_Color,
	MaxG >= G_Color,
	rdf_has(ObjectIdentifier, suturo:bColorValue , Obj_B_Color),
	strip_literal_type(Obj_B_Color, B_Raw),
	atom_number(B_Raw, B),	
	MinB is B - RGBVariance,
	MaxB is B + RGBVariance,
	MinB =< B_Color,
	MaxB >= B_Color.

hsvIsFitting(ObjectIdentifier, Step, H_Value, S_Value, V_Value) :-
	rdf_has(ObjectIdentifier, suturo:hColorValue , Obj_H_Value),
	hColorVariance(HVarianceRaw),
	varianceSteps(Steps),
	HVariance is (Step/Steps*HVarianceRaw),
	strip_literal_type(Obj_H_Value, H_Raw),
	atom_number(H_Raw, H),
	MinH is round(H - HVariance) mod 360,
	MaxH is round(H + HVariance) mod 360,
	(((H - HVariance) < 0; (H + HVariance) >359) -> 
		(MinH =< H_Value; MaxH >= H_Value);
		((MinH =< H_Value), (MaxH >= H_Value)) ),
	rdf_has(ObjectIdentifier, suturo:sColorValue , Obj_S_Value),
	svColorVariance(SVVarianceRaw),
	SVVariance is (Step/Steps*SVVarianceRaw),
	strip_literal_type(Obj_S_Value, S_Raw),
	atom_number(S_Raw, S),
	MinS is S - SVVariance,
	MaxS is S + SVVariance,
	MinS =< S_Value,
	MaxS >= S_Value,
	rdf_has(ObjectIdentifier, suturo:vColorValue , Obj_V_Value),
	strip_literal_type(Obj_V_Value, V_Raw),
	atom_number(V_Raw, V),
	MinV is V - SVVariance,
	MaxV is V + SVVariance,
	MinV =< V_Value,
	MaxV >= V_Value.

headElement([Head| _], Head).

%% This is a test for JNI integration
getPerceivedObjectsInfos(PODataList) :-
	perception(PrologBridge),
	jpl_call(PrologBridge, 'updatePerception', [], Out_raw),
	jpl_get(Out_raw,'length',Length),
	is(Indizees, Length-1),
	findall(POData,processPerceivedObjects(Out_raw, Indizees, POData), PODataList).

processPerceivedObjects(Out_raw, Indizees, Result) :-
	perception(PrologBridge),
	numlist(0,Indizees,IndexList),
	member(Index, IndexList),
	jpl_get(Out_raw,Index,Perceived_object),
	getPerceivedObjectInfos(Perceived_object, POData),
	headElement(POData, _c_id),
	jpl_call(PrologBridge, 'getOdomCoords', [_c_id], Odom_Raw),
	jpl_call(Odom_Raw, 'getData', [], Point_Raw),
	jpl_get(Point_Raw,'x', X_Coord),
	jpl_get(Point_Raw,'y', Y_Coord),
	jpl_get(Point_Raw,'z', Z_Coord),
	jpl_get(Odom_Raw,'frameID', Odom_FrameId),
	append(POData,[X_Coord, Y_Coord, Z_Coord, Odom_FrameId], Result).

getPerceivedObjectInfos(Obj_id, [_c_id, _c_centroid, _c_volume, _frame_id,
 _recognition_label_2d, _c_shape, _c_color_average_r, _c_color_average_g, _c_color_average_b,
 _c_color_average_h, _c_color_average_s, _c_color_average_v, _c_hue_histogram, _c_hue_histogram_quality]) :-
	jpl_get(Obj_id, 'c_id', _c_id),
	jpl_get(Obj_id, 'c_centroid', _c_centroid),
	jpl_get(Obj_id, 'c_volume', _c_volume),
	jpl_get(Obj_id, 'frame_id', _frame_id),
	jpl_get(Obj_id, 'recognition_label_2d', _recognition_label_2d),
	jpl_get(Obj_id, 'c_shape', _c_shape),
	jpl_get(Obj_id, 'c_color_average_r', _c_color_average_r),
	jpl_get(Obj_id, 'c_color_average_g', _c_color_average_g),
	jpl_get(Obj_id, 'c_color_average_b', _c_color_average_b),
	jpl_get(Obj_id, 'c_color_average_h', _c_color_average_h),
	jpl_get(Obj_id, 'c_color_average_s', _c_color_average_s),
	jpl_get(Obj_id, 'c_color_average_v', _c_color_average_v),
	jpl_get(Obj_id, 'c_hue_histogram', _c_hue_histogram),
	jpl_get(Obj_id, 'c_hue_histogram_quality', _c_hue_histogram_quality).

sendPlanningScene(ObjectList) :-
	mapconverter(MapConverter),
	foreach(member(Object, ObjectList), sendSingleObject(Object)),
	jpl_call(MapConverter, 'publishScene', [], _).

getLatestCoordinatesOfObject(ObjectIdentifier, X , Y ,Z, FrameID) :-
	rdf_has(ObjectIdentifier, knowrob:latestDetectionOfObject, ObjectDetection),
	rdf_has(ObjectDetection, suturo:frameID, FrameID_Raw),
	strip_literal_type(FrameID_Raw, FrameID),
	rdf_has(ObjectDetection, knowrob:eventOccursAt, RotationMatrix),
	rdf_has(RotationMatrix, knowrob:m03, X_Coord),
	strip_literal_type(X_Coord , X1),
	(rdf_has(ObjectIdentifier, suturo:xOffset, X_Offset) ->
		strip_literal_type(X_Offset , X2S), atom_number(X2S, X2), X is (X1+X2);
		X is X1),
	rdf_has(RotationMatrix, knowrob:m13, Y_Coord),
	strip_literal_type(Y_Coord, Y1),
	(rdf_has(ObjectIdentifier, suturo:yOffset, Y_Offset) ->
		strip_literal_type(Y_Offset , Y2S), atom_number(Y2S, Y2), Y is (Y1+Y2);
		Y is Y1),
	rdf_has(RotationMatrix, knowrob:m23, Z_Coord),
	strip_literal_type(Z_Coord, Z1),
	(rdf_has(ObjectIdentifier, suturo:zOffset, Z_Offset) ->
		strip_literal_type(Z_Offset , Z2S), atom_number(Z2S, Z2), Z is (Z1+Z2);
		Z is Z1).

sendSingleObject(ObjectIdentifier) :-
	mapconverter(MapConverter),
	rdf_has(ObjectIdentifier, knowrob:heightOfObject, OHeight),
	strip_literal_type(OHeight, Height_Raw),
	atom_number(Height_Raw, Height),
	rdf_has(ObjectIdentifier, knowrob:depthOfObject, ODepth),
	strip_literal_type(ODepth, Depth_Raw),
	atom_number(Depth_Raw, Depth),
	rdf_has(ObjectIdentifier, knowrob:widthOfObject, OWidth),
	strip_literal_type(OWidth, Width_Raw),
	atom_number(Width_Raw, Width),
	getLatestCoordinatesOfObject(ObjectIdentifier, X_Coord, Y_Coord, Z_Coord, FrameID),
	jpl_call(MapConverter, 'addBox', [ObjectIdentifier, Depth, Width, Height, X_Coord, Y_Coord, Z_Coord, FrameID], _).
